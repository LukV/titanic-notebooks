{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic competition - Random Forest\n",
    "This notebook applies the Random Forest machine learning algorithm in Python3 to tackle the Kaggle Titanic competition. It uses the exact approach described in the Datacamp open course *Kaggle Python Tutorial on Machine Learning*.\n",
    "\n",
    "We will follow these steps:\n",
    "1. import the required libraries and get the data\n",
    "2. describe the data\n",
    "3. clean and format data\n",
    "4. train the model\n",
    "5. predict and submit to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data with Pandas\n",
    "Load in the training and testing set into your Python environment. The data is stored on the web as csv files. Load this data with the read_csv() method from the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import the Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Import the Numpy library\n",
    "import numpy as np\n",
    "\n",
    "# Import the RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Disable the SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Load the train and test datasets to create two DataFrames\n",
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "\n",
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "test = pd.read_csv(test_url)\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the data\n",
    "\n",
    "[Titanic competition - Decision Tree](Titanic%20competition%20-%20Decision%20Tree.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the Age variable\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "\n",
    "# Convert the male and female groups to integer form\n",
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "# Impute the Embarked variable\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# Convert the Embarked classes to integer form\n",
    "#train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "#train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "#train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n",
    "\n",
    "# Impute the Age and Fare variables\n",
    "test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n",
    "test[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())\n",
    "\n",
    "# Convert the male and female groups to integer form\n",
    "test[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\n",
    "test[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "# Impute the Embarked variable\n",
    "test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# Convert the Embarked classes to integer form\n",
    "#test[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\n",
    "#test[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\n",
    "#test[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "the Random Forest technique handles the overfitting problem with decision trees. It grows multiple (very deep) classification trees using the training set. At the time of prediction, each tree is used to come up with a prediction and every outcome is counted as a vote. For example, if you have trained 3 trees with 2 saying a passenger in the test set will survive and 1 says he will not, the passenger will be classified as a survivor. This approach of overtraining trees, but having the majority's vote count as the actual classification decision, avoids overfitting.\n",
    "\n",
    "Building a random forest in Python looks almost the same as building a decision tree. There are two key differences. A different class is used and a new argument is necessary. Also, we need to import the necessary library from scikit-learn.\n",
    "* Use RandomForestClassifier() class instead of the DecisionTreeClassifier() class.\n",
    "* n_estimators needs to be set when using the RandomForestClassifier() class. This argument allows you to set the number of trees you wish to plant and average over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "# Create the target and features numpy arrays: target, features_one\n",
    "target = train[\"Survived\"].values\n",
    "features_forest = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\"]].values\n",
    "\n",
    "# Building and fitting my_forest\n",
    "forest = RandomForestClassifier(max_depth = 10, min_samples_split=2, n_estimators = 100, random_state = 1)\n",
    "my_forest = forest.fit(features_forest, target)\n",
    "\n",
    "# Print the score of the fitted random forest\n",
    "print(my_forest.score(features_forest, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and submit to Kaggle\n",
    "\n",
    "make use of the `.predict()` method. You provide it the model (`my_tree_one`), the values of features from the dataset for which predictions need to be made (`test`).\n",
    "\n",
    "make sure your output is in line with the submission requirements of Kaggle: a csv file with exactly 418 entries and two columns: `PassengerId` and `Survived`. Then use the code provided to make a new data frame using DataFrame(), and create a csv file using to_csv() method from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n",
      "      Survived\n",
      "892          0\n",
      "893          0\n",
      "894          0\n",
      "895          0\n",
      "896          0\n",
      "897          0\n",
      "898          0\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          0\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          0\n",
      "910          0\n",
      "911          0\n",
      "912          0\n",
      "913          1\n",
      "914          1\n",
      "915          0\n",
      "916          1\n",
      "917          0\n",
      "918          1\n",
      "919          0\n",
      "920          1\n",
      "921          0\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         0\n",
      "1283         1\n",
      "1284         0\n",
      "1285         0\n",
      "1286         0\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         0\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         0\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         1\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n",
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Compute predictions on our test set features then print the length of the prediction vector\n",
    "test_features = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\"]].values\n",
    "pred_forest = my_forest.predict(test_features)\n",
    "print(len(pred_forest))\n",
    "\n",
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(pred_forest, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_two.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
