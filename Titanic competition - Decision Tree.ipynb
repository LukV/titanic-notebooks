{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic competition - Decision Tree\n",
    "This notebook applies the Decision Tree machine learning algorithm in Python3 to tackle the Kaggle Titanic competition. It uses the exact approach described in the Datacamp open course *Kaggle Python Tutorial on Machine Learning*.\n",
    "\n",
    "We will follow these steps:\n",
    "1. import the required libraries and get the data\n",
    "2. describe the data\n",
    "3. clean and format data\n",
    "4. create decision tree\n",
    "5. predict and submit to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data with Pandas\n",
    "Load in the training and testing set into your Python environment. The data is stored on the web as csv files. Load this data with the read_csv() method from the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "\n",
      "   Parch     Ticket     Fare Cabin Embarked  \n",
      "0      0  A/5 21171   7.2500   NaN        S  \n",
      "1      0   PC 17599  71.2833   C85        C  \n"
     ]
    }
   ],
   "source": [
    "# Import the Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Import the Numpy library\n",
    "import numpy as np\n",
    "\n",
    "# Import 'tree' from scikit-learn library\n",
    "from sklearn import tree\n",
    "\n",
    "# Disable the SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Load the train and test datasets to create two DataFrames\n",
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "\n",
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "test = pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the data\n",
    "\n",
    "Both test and train are DataFrame objects, the way pandas represent datasets. You can explore a DataFrame using the `.describe()` method. Another useful trick is to look at the dimensions of the DataFrame. This is done by requesting the `.shape` attribute of your DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Child'],\n",
      "      dtype='object')\n",
      "____________________\n",
      "\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
      "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare       Child  \n",
      "count  891.000000  891.000000  714.000000  \n",
      "mean     0.381594   32.204208    0.158263  \n",
      "std      0.806057   49.693429    0.365244  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    7.910400    0.000000  \n",
      "50%      0.000000   14.454200    0.000000  \n",
      "75%      0.000000   31.000000    0.000000  \n",
      "max      6.000000  512.329200    1.000000  \n",
      "____________________\n",
      "\n",
      "shape (891, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print('_' * 20 + '\\n')\n",
    "print(train.describe())\n",
    "print('_' * 20  + '\\n')\n",
    "print('shape', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many people in your training set survived the disaster with the Titanic? To see this, you can use the value_counts() method in combination with standard bracket notation to select a single column of a DataFrame:\n",
    "\n",
    "We can perform similar counts and percentage calculations on subsets of the Survived column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: Survived, dtype: float64\n",
      "0    468\n",
      "1    109\n",
      "Name: Survived, dtype: int64\n",
      "0    0.811092\n",
      "1    0.188908\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Passengers that survived vs passengers that passed away\n",
    "print(train[\"Survived\"].value_counts())\n",
    "\n",
    "# As proportions\n",
    "print(train[\"Survived\"].value_counts(normalize = True))\n",
    "\n",
    "# Males that survived \n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts())\n",
    "\n",
    "# Normalized male survival\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "5      NaN\n",
      "6      0.0\n",
      "7      1.0\n",
      "8      0.0\n",
      "9      1.0\n",
      "10     1.0\n",
      "11     0.0\n",
      "12     0.0\n",
      "13     0.0\n",
      "14     1.0\n",
      "15     0.0\n",
      "16     1.0\n",
      "17     NaN\n",
      "18     0.0\n",
      "19     NaN\n",
      "20     0.0\n",
      "21     0.0\n",
      "22     1.0\n",
      "23     0.0\n",
      "24     1.0\n",
      "25     0.0\n",
      "26     NaN\n",
      "27     0.0\n",
      "28     NaN\n",
      "29     NaN\n",
      "      ... \n",
      "861    0.0\n",
      "862    0.0\n",
      "863    NaN\n",
      "864    0.0\n",
      "865    0.0\n",
      "866    0.0\n",
      "867    0.0\n",
      "868    NaN\n",
      "869    1.0\n",
      "870    0.0\n",
      "871    0.0\n",
      "872    0.0\n",
      "873    0.0\n",
      "874    0.0\n",
      "875    1.0\n",
      "876    0.0\n",
      "877    0.0\n",
      "878    NaN\n",
      "879    0.0\n",
      "880    0.0\n",
      "881    0.0\n",
      "882    0.0\n",
      "883    0.0\n",
      "884    0.0\n",
      "885    0.0\n",
      "886    0.0\n",
      "887    0.0\n",
      "888    NaN\n",
      "889    0.0\n",
      "890    0.0\n",
      "Name: Child, Length: 891, dtype: float64\n",
      "1    0.539823\n",
      "0    0.460177\n",
      "Name: Survived, dtype: float64\n",
      "0    0.618968\n",
      "1    0.381032\n",
      "Name: Survived, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lve/code/python/jupyter/env/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/lve/code/python/jupyter/env/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create the column Child and assign to 'NaN'\n",
    "train[\"Child\"] = float('NaN')\n",
    "\n",
    "# Assign 1 to passengers under 18, 0 to those 18 or older. Print the new column.\n",
    "train[\"Child\"][train[\"Age\"] >= 18] = 0\n",
    "train[\"Child\"][train[\"Age\"] < 18] = 1\n",
    "print(train[\"Child\"])\n",
    "\n",
    "# Print normalized Survival Rates for passengers under 18\n",
    "print(train[\"Survived\"][train[\"Child\"] == 1].value_counts(normalize = True))\n",
    "\n",
    "# Print normalized Survival Rates for passengers 18 or older\n",
    "print(train[\"Survived\"][train[\"Child\"] == 0].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and format data\n",
    "\n",
    "Add a new variable `Child` (i) create a new column, and (ii) provide the values for each observation (i.e., row) based on the age of the passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.539823\n",
      "0    0.460177\n",
      "Name: Survived, dtype: float64\n",
      "0    0.618968\n",
      "1    0.381032\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create the column Child and assign to 'NaN'\n",
    "train[\"Child\"] = float('NaN')\n",
    "\n",
    "# Assign 1 to passengers under 18, 0 to those 18 or older. Print the new column.\n",
    "train[\"Child\"][train[\"Age\"] >= 18] = 0\n",
    "train[\"Child\"][train[\"Age\"] < 18] = 1\n",
    "\n",
    "# Print normalized Survival Rates for passengers under 18\n",
    "print(train[\"Survived\"][train[\"Child\"] == 1].value_counts(normalize = True))\n",
    "\n",
    "# Print normalized Survival Rates for passengers 18 or older\n",
    "print(train[\"Survived\"][train[\"Child\"] == 0].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Age variable had some missing value. Use a imputation technique to substitute each missing value with the median of the all present values.\n",
    "\n",
    "The Sex and Embarked variables are categorical but in a non-numeric format. We need to assign each class a unique integer so that Python can handle the information. Embarked also has some missing values which we impute with the most common class of embarkation, which is \"S\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the Age variable\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "\n",
    "# Convert the male and female groups to integer form\n",
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "# Impute the Embarked variable\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# Convert the Embarked classes to integer form\n",
    "#train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "#train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "#train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create decision tree\n",
    "\n",
    "Use `scikit-learn` and `numpy` libraries to build a decision tree. scikit-learn can be used to create tree objects from the `DecisionTreeClassifier` class. The methods we use take numpy arrays as inputs and therefore we will need to create those from the DataFrame that we already have. \n",
    "\n",
    "To quickly see the result of your decision tree see the importance of the features that are included. This is done by requesting the `.feature_importances_` attribute of your tree object. Another metric is the mean accuracy that you can compute using the `.score()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16349413 0.42846618 0.16408928 0.2439504 ]\n",
      "0.9001122334455668\n"
     ]
    }
   ],
   "source": [
    "# Create the target and features numpy arrays: target, features_one\n",
    "target = train[\"Survived\"].values\n",
    "features_one = train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "\n",
    "#Control overfitting by setting \"max_depth\" to 10 and \"min_samples_split\" to 5 : my_tree_two\n",
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "\n",
    "# Fit your first decision tree: my_tree_one\n",
    "my_tree_one = tree.DecisionTreeClassifier(max_depth = max_depth, \n",
    "                                          min_samples_split = min_samples_split, \n",
    "                                          random_state = 1)\n",
    "my_tree_one = my_tree_one.fit(features_one, target)\n",
    "\n",
    "# Look at the importance and score of the included features\n",
    "print(my_tree_one.feature_importances_)\n",
    "print(my_tree_one.score(features_one, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and submit to Kaggle\n",
    "\n",
    "make use of the `.predict()` method. You provide it the model (`my_tree_one`), the values of features from the dataset for which predictions need to be made (`test`).\n",
    "\n",
    "make sure your output is in line with the submission requirements of Kaggle: a csv file with exactly 418 entries and two columns: `PassengerId` and `Survived`. Then use the code provided to make a new data frame using DataFrame(), and create a csv file using to_csv() method from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      " 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n",
      "      Survived\n",
      "892          0\n",
      "893          0\n",
      "894          0\n",
      "895          0\n",
      "896          1\n",
      "897          0\n",
      "898          0\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          0\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          0\n",
      "910          1\n",
      "911          0\n",
      "912          0\n",
      "913          1\n",
      "914          1\n",
      "915          1\n",
      "916          1\n",
      "917          0\n",
      "918          1\n",
      "919          0\n",
      "920          0\n",
      "921          0\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         1\n",
      "1283         1\n",
      "1284         0\n",
      "1285         0\n",
      "1286         0\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         1\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         0\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         1\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n",
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "# Impute the missing value with the median\n",
    "test.Fare[152] = test[\"Fare\"].median()\n",
    "\n",
    "# Impute the Age variable\n",
    "test[\"Age\"] = test[\"Age\"].fillna(train[\"Age\"].median())\n",
    "\n",
    "# Convert the male and female groups to integer form\n",
    "test[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\n",
    "test[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "# Extract the features from the test set: Pclass, Sex, Age, and Fare.\n",
    "test_features = test[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "\n",
    "# Make your prediction using the test set\n",
    "my_prediction = my_tree_one.predict(test_features)\n",
    "print(my_prediction)\n",
    "\n",
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_one.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
